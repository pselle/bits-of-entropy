<html>
  <head>
    <meta charset="utf-8">
    <title>Calculating Shannon Entropy</title>
    <link href="src/style.css" rel="stylesheet">
  </head>
  <body>
    <h1>Bits of Entropy</h1>
    <p>Shannon entropy was introduced by Claude E. Shannon in the 1948 paper "A Mathematical Theory of Communication". It's this equation:</p>
    <img src="src/public/entropyequation.jpg" />

    <p>Shannon entropy is the "average minimum number of bits needed to encode a string of symbols, based on the frequency of the symbols" (<a href="http://www.bearcave.com/misl/misl_tech/wavelets/compression/shannon.html" alt="Bear Cave article on Shannon entropy">source</a>).</p>

    <p>Imagine that you and your friends have decided to communicate in an emoji-only protocol. Each emoji is a message. But some messages are more common than others â€“ ex. ğŸ˜€ is more commonly used among your friends than ğŸ­. Another way of saying that is that has a higher probability of appearing in a given message than ğŸ­.</p>

    <p>So in this Shannon entropy calculator, our <strong>symbols</strong> are emoji, and each member of the set has a different probability of being represented in a given message. As you change the probabilities, make sure they add up to 1 (100%) since otherwise your probability distribution is incomplete.</p>

    <p>You have 5 emoji to start with, and you can add and remove emoji to see how the number of items in the set impacts the entropy!</p>
    <div id="app" />
    <script src="src/public/bundle.js" type="text/javascript"></script>
  </body>
</html>